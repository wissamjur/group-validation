{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# change dir for custom imports\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_name = 'ml-1m'\n",
    "\n",
    "testset = pd.read_csv('output/' + dataset_name + '/test.csv')\n",
    "all_predictions = pd.read_csv('output/' + dataset_name + '/all_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "k = 10\n",
    "eval_map = map_at_k(testset, all_predictions, col_user='userId', col_item='movieId', col_prediction='prediction', k=k)\n",
    "eval_ndcg = ndcg_at_k(testset, all_predictions, col_user='userId', col_item='movieId', col_prediction='prediction', k=k)\n",
    "eval_precision = precision_at_k(testset, all_predictions, col_user='userId', col_item='movieId', col_prediction='prediction', k=k)\n",
    "eval_recall = recall_at_k(testset, all_predictions, col_user='userId', col_item='movieId', col_prediction='prediction', k=k)\n",
    "\n",
    "# print(\n",
    "#     \"MAP:\\t%f\" % eval_map,\n",
    "#     \"NDCG:\\t%f\" % eval_ndcg,\n",
    "#     \"Precision@K:\\t%f\" % eval_precision,\n",
    "#     \"Recall@K:\\t%f\" % eval_recall, sep='\\n'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1605</td>\n",
       "      <td>3549</td>\n",
       "      <td>4.083208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1605</td>\n",
       "      <td>2370</td>\n",
       "      <td>3.528950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1605</td>\n",
       "      <td>1959</td>\n",
       "      <td>2.961816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1605</td>\n",
       "      <td>3594</td>\n",
       "      <td>3.412933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1605</td>\n",
       "      <td>2091</td>\n",
       "      <td>3.090755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16218226</th>\n",
       "      <td>4355</td>\n",
       "      <td>3772</td>\n",
       "      <td>3.556495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16218227</th>\n",
       "      <td>4355</td>\n",
       "      <td>3828</td>\n",
       "      <td>3.517083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16218228</th>\n",
       "      <td>4355</td>\n",
       "      <td>3904</td>\n",
       "      <td>3.752912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16218229</th>\n",
       "      <td>4355</td>\n",
       "      <td>3722</td>\n",
       "      <td>3.530454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16218230</th>\n",
       "      <td>4355</td>\n",
       "      <td>3748</td>\n",
       "      <td>3.971879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16218231 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  prediction\n",
       "0           1605     3549    4.083208\n",
       "1           1605     2370    3.528950\n",
       "2           1605     1959    2.961816\n",
       "3           1605     3594    3.412933\n",
       "4           1605     2091    3.090755\n",
       "...          ...      ...         ...\n",
       "16218226    4355     3772    3.556495\n",
       "16218227    4355     3828    3.517083\n",
       "16218228    4355     3904    3.752912\n",
       "16218229    4355     3722    3.530454\n",
       "16218230    4355     3748    3.971879\n",
       "\n",
       "[16218231 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import merge_ranking_true_pred\n",
    "\n",
    "k = 10\n",
    "col_user = \"userId\"\n",
    "col_item = \"movieId\"\n",
    "col_rating = \"rating\"\n",
    "col_prediction = \"prediction\"\n",
    "\n",
    "df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "    rating_true=testset,\n",
    "    rating_pred=all_predictions,\n",
    "    col_user=col_user,\n",
    "    col_item=col_item,\n",
    "    col_rating=col_rating,\n",
    "    col_prediction=col_prediction,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate discounted gain for hit items\n",
    "df_dcg = df_hit.copy()\n",
    "# relevance in this case is always 1\n",
    "df_dcg[\"dcg\"] = 1 / np.log1p(df_dcg[\"rank\"])\n",
    "# sum up discount gained to get discount cumulative gain\n",
    "df_dcg = df_dcg.groupby(col_user, as_index=False, sort=False).agg({\"dcg\": \"sum\"})\n",
    "# calculate ideal discounted cumulative gain\n",
    "df_ndcg = pd.merge(df_dcg, df_hit_count, on=[col_user])\n",
    "df_ndcg[\"idcg\"] = df_ndcg[\"actual\"].apply(\n",
    "    lambda x: sum(1 / np.log1p(range(1, min(x, k) + 1)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nDCG and precision equations\n",
    "ndcg = (df_ndcg[\"dcg\"] / df_ndcg[\"idcg\"]).sum() / n_users\n",
    "precision = (df_hit_count[\"hit\"] / k).sum() / n_users\n",
    "recall = (df_hit_count[\"hit\"] / df_hit_count[\"actual\"]).sum() / n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Metric - nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = pd.read_csv('output/' + dataset_name + '/clusters.csv')\n",
    "\n",
    "# group clusters into another dataframe with different representation\n",
    "grouped_clusters = clustered_df.groupby('cluster')['userId'].apply(list).reset_index(name='users_list')\n",
    "grouped_clusters['users_per_cluster'] = grouped_clusters.apply(lambda x: list(set(x.users_list)), axis=1)\n",
    "grouped_clusters = grouped_clusters[['cluster', 'users_per_cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_metric = {}\n",
    "all_clusters_list = grouped_clusters.users_per_cluster.to_list()\n",
    "all_users = len(set(all_predictions.userId.to_list()))\n",
    "\n",
    "for cluster_id, cluster in enumerate(all_clusters_list):\n",
    "    # users in the cluster vs. users in the equiv group\n",
    "    n_cluster_users = len(cluster)\n",
    "    n_cluster_users_equiv = all_users - n_cluster_users\n",
    "\n",
    "    df_ndcg_cluster = df_ndcg.loc[df_ndcg[\"userId\"].isin(cluster)]\n",
    "    df_ndcg_cluster_equiv = df_ndcg.loc[~df_ndcg['userId'].isin(cluster)]\n",
    "\n",
    "    # group metrics\n",
    "    cluster_ndcg = (df_ndcg_cluster[\"dcg\"] / df_ndcg_cluster[\"idcg\"]).sum() / n_cluster_users\n",
    "    cluster_precision = (df_ndcg_cluster[\"hit\"] / k).sum() / n_cluster_users\n",
    "    cluster_recall = (df_ndcg_cluster[\"hit\"] / df_ndcg_cluster[\"actual\"]).sum() / n_cluster_users\n",
    "\n",
    "    # group equiv. metrics\n",
    "    cluster_ndcg_equiv = (df_ndcg_cluster_equiv[\"dcg\"] / df_ndcg_cluster_equiv[\"idcg\"]).sum() / n_cluster_users_equiv\n",
    "    cluster_precision_equiv = (df_ndcg_cluster_equiv[\"hit\"] / k).sum() / n_cluster_users_equiv\n",
    "    cluster_recall_equiv = (df_ndcg_cluster_equiv[\"hit\"] / df_ndcg_cluster_equiv[\"actual\"]).sum() / n_cluster_users_equiv\n",
    "\n",
    "    group_metric[cluster_id] = [\n",
    "        cluster_ndcg,\n",
    "        cluster_ndcg_equiv,\n",
    "        cluster_precision,\n",
    "        cluster_precision_equiv,\n",
    "        cluster_recall,\n",
    "        cluster_recall_equiv\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_metric_df = pd.DataFrame.from_dict(group_metric, orient='index')\\\n",
    "    .reset_index()\\\n",
    "    .rename({\n",
    "        'index': 'cluster',\n",
    "        0: 'cluster-nDCG',\n",
    "        1: 'cluster-nDCG-eq',\n",
    "        2: 'cluster-precision',\n",
    "        3: 'cluster-precision-eq',\n",
    "        4: 'cluster-recall',\n",
    "        5: 'cluster-recall-eq'\n",
    "        }, axis=1)\n",
    "group_metric_df['ndcg'] = ndcg\n",
    "group_metric_df['precision'] = precision\n",
    "group_metric_df['recall'] = recall\n",
    "\n",
    "# save results in csv\n",
    "group_metric_df.to_csv('validation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group-validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4bfbead4e2efcc94ee2a715a30957ed380184240733e2fa0165fb50dafa7065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
