{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# change dir for custom imports\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from helpers.dataset_helpers import get_genres_as_columns, get_all_genres_list\n",
    "from metric.helpers import (\n",
    "    get_user_genre_list,\n",
    "    get_user_max_likelihood,\n",
    "    get_ideal_rankings,\n",
    "    build_all_likelihood_dict\n",
    ")\n",
    "\n",
    "dataset_name = 'ml-25m'\n",
    "# original data from the dataset\n",
    "ratings = pd.read_csv('datasets/' + dataset_name + '/shrunk/ratings_small_v2.csv')\n",
    "movies = pd.read_csv('datasets/' + dataset_name + '/movies.csv')\n",
    "\n",
    "# data from recommender\n",
    "testset = pd.read_csv('output/' + dataset_name + '/test.csv')\n",
    "# if there's synthetic data, add it to the test set.\n",
    "# the idea is that the new synthetic data will have different indexes, \n",
    "# so we look for those new indexes that are not found in the initial dataset.\n",
    "midified_ratings = pd.read_csv('datasets/' + dataset_name + '/modified/ratings_random_experiment.csv', usecols=['userId', 'movieId', 'rating'])\n",
    "synthetic_data = midified_ratings.loc[~midified_ratings.index.isin(ratings.index.to_list())]\n",
    "# concat the synthetic data with the test set\n",
    "testset = pd.concat([testset, synthetic_data])\n",
    "trainset = pd.read_csv('output/' + dataset_name + '/train.csv')\n",
    "rankings = pd.read_csv('output/' + dataset_name + '/rankings.csv')\n",
    "\n",
    "# merge item data to the ratings df\n",
    "test_df = testset.merge(movies, how='inner', on='movieId').sort_values(by='userId')\n",
    "ratings_df = ratings.merge(movies, how='inner', on='movieId').sort_values(by='userId')\n",
    "rankings_df = rankings.merge(movies, how='inner', on='movieId').sort_values(by='rank').drop('title', axis=1)\n",
    "\n",
    "# create a new column for the genres count\n",
    "test_df['count_genres'] = test_df.apply(lambda x: len(x['genres'].split('|')), axis=1)\n",
    "\n",
    "# get all unique genres and users\n",
    "genres = get_all_genres_list(ratings_df)\n",
    "users = list(set(ratings_df.userId.to_list()))\n",
    "\n",
    "# merge rankings with the real ratings\n",
    "rankings_hits = rankings_df.merge(ratings_df, how='left', on=['userId', 'movieId', 'genres']).sort_values(by=['userId', 'rank'])\n",
    "rankings_hits = rankings_hits.drop(['title', 'timestamp'], axis=1)\n",
    "\n",
    "# build the likelihood dict (dictionary will be saved in ./output/dataset)\n",
    "# can be build it once per dataset (if we run group validation multiple times and vary some parameters)\n",
    "# build_all_likelihood_dict(users, genres, ratings_df, dataset_name)\n",
    "# load user likelihood data\n",
    "with open('output/' + dataset_name + '/likelihood.pkl', 'rb') as pkl_handle:\n",
    "\tlikelihood_dict = pickle.load(pkl_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small example on user likelihood - could be skipped\n",
    "# get user likelihood value example\n",
    "user_id = 12\n",
    "target_genre = 'Action'\n",
    "\n",
    "get_user_max_likelihood(user_id, target_genre, genres, ratings_df)\n",
    "# user offline dict for likelihood\n",
    "likelihood_dict[target_genre][user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering - kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = pd.read_csv('output/' + dataset_name + '/clusters.csv')\n",
    "\n",
    "# group clusters into another dataframe with different representation\n",
    "grouped_clusters = clustered_df.groupby('cluster')['userId'].apply(list).reset_index(name='users_list')\n",
    "grouped_clusters['users_per_cluster'] = grouped_clusters.apply(lambda x: list(set(x.users_list)), axis=1)\n",
    "grouped_clusters = grouped_clusters[['cluster', 'users_per_cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_clusters.users_per_cluster.to_list()[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation - alpha-beta-ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get ideal rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_users = []\n",
    "ideal_rankings = []\n",
    "k = 5\n",
    "# get ideal rankings for every unique user in the dataset\n",
    "for user in users:\n",
    "    # check if ratings of user in the test_df is less than k\n",
    "    if len(test_df[test_df['userId'] == user]) <= k:\n",
    "        discarded_users.append(user)\n",
    "        continue\n",
    "\n",
    "    user_ideal_ranks = get_ideal_rankings(user, likelihood_dict, test_df, k=k)\n",
    "    df = pd.DataFrame(user_ideal_ranks, columns=[\"userId\", \"movieId\", \"prediction\", \"rank\"])\n",
    "    ideal_rankings.append(df)\n",
    "\n",
    "user_ideal_ranks_df = pd.concat(ideal_rankings)\n",
    "\n",
    "# merge item data to the ratings df and then left joing to get real ratings\n",
    "user_ideal_ranks_df = user_ideal_ranks_df.merge(movies, how='inner', on='movieId').sort_values(by='userId')\n",
    "user_ideal_ranks_df = user_ideal_ranks_df.merge(ratings_df, how='left', on=['userId', 'movieId', 'genres', 'title']).sort_values(by=['userId', 'rank'])\n",
    "user_ideal_ranks_df = user_ideal_ranks_df.drop(['title', 'timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ideal_ranks_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha-beta-nDCG - Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(discarded_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric.metric import transform_rankings_hits, get_user_dcg, get_dcg\n",
    "\n",
    "rankings_hits_transformed = transform_rankings_hits(rankings_hits, genres)\n",
    "rankings_hits_transformed_ideal = transform_rankings_hits(user_ideal_ranks_df, genres)\n",
    "\n",
    "user_id = 12\n",
    "k = 5\n",
    "user_dcg = get_user_dcg(user_id, rankings_hits_transformed, ratings_df, likelihood_dict, k)\n",
    "user_idcg = get_user_dcg(user_id, rankings_hits_transformed_ideal, ratings_df, likelihood_dict, k)\n",
    "user_idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha-beta-nDCG for the whole test data\n",
    "dcg = get_dcg(rankings_hits_transformed, ratings_df, likelihood_dict, discarded_users, k)\n",
    "idcg = get_dcg(rankings_hits_transformed_ideal, ratings_df, likelihood_dict, discarded_users, k)\n",
    "\n",
    "alpha_beta_ndcg = dcg[0]/idcg[0]\n",
    "alpha_beta_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcg_df = dcg[1]\n",
    "idcg_df = idcg[1]\n",
    "all_clusters_list = grouped_clusters.users_per_cluster.to_list()\n",
    "print(all_clusters_list[0])\n",
    "test_array = all_clusters_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dcg_df = dcg_df.loc[~dcg_df['userId'].isin(test_array)]\n",
    "cluster_dcg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcg_df = dcg[1]\n",
    "idcg_df = idcg[1]\n",
    "all_clusters_list = grouped_clusters.users_per_cluster.to_list()\n",
    "group_metric = {}\n",
    "\n",
    "for cluster_id, cluster in enumerate(all_clusters_list):\n",
    "    # dcg/idcg for the cluster\n",
    "    cluster_dcg_df = dcg_df.loc[dcg_df['userId'].isin(cluster)]\n",
    "    cluster_idcg_df = idcg_df.loc[idcg_df['userId'].isin(cluster)]\n",
    "    cluster_dcg = sum(cluster_dcg_df['DCG'].to_list())\n",
    "    cluster_idcg = sum(cluster_idcg_df['DCG'].to_list())\n",
    "    # cluster ab-nDCG\n",
    "    cluster_alpha_beta_ndcg = cluster_dcg/cluster_idcg\n",
    "\n",
    "    # dcg/idcg for the equivalent (cluster - dataset = rest of the examples)\n",
    "    cluster_equiv_dcg_df = dcg_df.loc[~dcg_df['userId'].isin(cluster)]\n",
    "    cluster_equiv_idcg_df = idcg_df.loc[~idcg_df['userId'].isin(cluster)]\n",
    "    cluster_equiv_dcg = sum(cluster_equiv_dcg_df['DCG'].to_list())\n",
    "    cluster_equiv_idcg = sum(cluster_equiv_idcg_df['DCG'].to_list())\n",
    "    # equivalent set ab-nDCG\n",
    "    cluster_equiv_alpha_beta_ndcg = cluster_equiv_dcg/cluster_equiv_idcg\n",
    "\n",
    "    group_metric[cluster_id] = [cluster_alpha_beta_ndcg, cluster_equiv_alpha_beta_ndcg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_metric_df = pd.DataFrame.from_dict(group_metric, orient='index')\\\n",
    "    .reset_index()\\\n",
    "    .rename({'index':'cluster', 0:'cluster-ab-nDCG', 1: 'equiv-ab-nDCG'}, axis=1)\n",
    "group_metric_df['ab-ndcg'] = alpha_beta_ndcg\n",
    "group_metric_df['perc-change'] = group_metric_df.apply(lambda x: ((x['cluster-ab-nDCG'] - x['ab-ndcg']) / x['ab-ndcg'])*100, axis=1)\n",
    "group_metric_df['condition-1'] = group_metric_df.apply(lambda x: (x['cluster-ab-nDCG'] - x['equiv-ab-nDCG']), axis=1)\n",
    "group_metric_df.to_csv('group_ndcg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('group-validation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52445fb09f682e9366639e37a6414f541c6481f599d97ed36cba6ef55ea50917"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
