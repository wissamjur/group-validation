{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# change dir for custom imports\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_name = 'ml-latest-small'\n",
    "\n",
    "testset = pd.read_csv('output/' + dataset_name + '/test.csv')\n",
    "all_predictions = pd.read_csv('output/' + dataset_name + '/all_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.040953\n",
      "NDCG:\t0.233171\n",
      "Precision@K:\t0.214638\n",
      "Recall@K:\t0.080423\n"
     ]
    }
   ],
   "source": [
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "k = 10\n",
    "eval_map = map_at_k(testset, all_predictions, col_user='userId', col_item='movieId', col_prediction='prediction', k=k)\n",
    "eval_ndcg = ndcg_at_k(testset, all_predictions, col_user='userId', col_item='movieId', col_prediction='prediction', k=k)\n",
    "eval_precision = precision_at_k(testset, all_predictions, col_user='userId', col_item='movieId', col_prediction='prediction', k=k)\n",
    "eval_recall = recall_at_k(testset, all_predictions, col_user='userId', col_item='movieId', col_prediction='prediction', k=k)\n",
    "\n",
    "print(\n",
    "    \"MAP:\\t%f\" % eval_map,\n",
    "    \"NDCG:\\t%f\" % eval_ndcg,\n",
    "    \"Precision@K:\\t%f\" % eval_precision,\n",
    "    \"Recall@K:\\t%f\" % eval_recall, sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nDCG Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import merge_ranking_true_pred\n",
    "\n",
    "col_user = \"userId\"\n",
    "col_item = \"movieId\"\n",
    "col_rating = \"rating\"\n",
    "col_prediction = \"prediction\"\n",
    "\n",
    "df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "    rating_true=testset,\n",
    "    rating_pred=all_predictions,\n",
    "    col_user=col_user,\n",
    "    col_item=col_item,\n",
    "    col_rating=col_rating,\n",
    "    col_prediction=col_prediction,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate discounted gain for hit items\n",
    "df_dcg = df_hit.copy()\n",
    "# relevance in this case is always 1\n",
    "df_dcg[\"dcg\"] = 1 / np.log1p(df_dcg[\"rank\"])\n",
    "# sum up discount gained to get discount cumulative gain\n",
    "df_dcg = df_dcg.groupby(col_user, as_index=False, sort=False).agg({\"dcg\": \"sum\"})\n",
    "# calculate ideal discounted cumulative gain\n",
    "df_ndcg = pd.merge(df_dcg, df_hit_count, on=[col_user])\n",
    "df_ndcg[\"idcg\"] = df_ndcg[\"actual\"].apply(\n",
    "    lambda x: sum(1 / np.log1p(range(1, min(x, k) + 1)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCG over IDCG is the normalized DCG\n",
    "ndcg = (df_ndcg[\"dcg\"] / df_ndcg[\"idcg\"]).sum() / n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (df_hit_count[\"hit\"] / k).sum() / n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Metric - nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = pd.read_csv('output/' + dataset_name + '/clusters.csv')\n",
    "\n",
    "# group clusters into another dataframe with different representation\n",
    "grouped_clusters = clustered_df.groupby('cluster')['userId'].apply(list).reset_index(name='users_list')\n",
    "grouped_clusters['users_per_cluster'] = grouped_clusters.apply(lambda x: list(set(x.users_list)), axis=1)\n",
    "grouped_clusters = grouped_clusters[['cluster', 'users_per_cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_metric = {}\n",
    "all_clusters_list = grouped_clusters.users_per_cluster.to_list()\n",
    "\n",
    "for cluster_id, cluster in enumerate(all_clusters_list):\n",
    "    n__cluster_users = len(cluster)\n",
    "    df_ndcg_cluster = df_ndcg.loc[df_ndcg[\"userId\"].isin(cluster)]\n",
    "\n",
    "    # DCG over IDCG is the normalized DCG\n",
    "    cluster_ndcg = (df_ndcg_cluster[\"dcg\"] / df_ndcg_cluster[\"idcg\"]).sum() / n__cluster_users\n",
    "    cluster_precision = (df_ndcg_cluster[\"hit\"] / k).sum() / n__cluster_users\n",
    "\n",
    "    group_metric[cluster_id] = [cluster_ndcg, cluster_precision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_metric_df = pd.DataFrame.from_dict(group_metric, orient='index')\\\n",
    "    .reset_index()\\\n",
    "    .rename({'index':'cluster', 0:'cluster-nDCG', 1: 'cluster-precision'}, axis=1)\n",
    "group_metric_df['ndcg'] = ndcg\n",
    "group_metric_df['precision'] = ndcg\n",
    "\n",
    "# save results in csv\n",
    "group_metric_df.to_csv('group_ndcg_with_synthetic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52445fb09f682e9366639e37a6414f541c6481f599d97ed36cba6ef55ea50917"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
