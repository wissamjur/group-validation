{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM model is only supported on Linux.\n",
      "Windows executable can be found at http://www.libfm.org.\n",
      "System version: 3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]\n",
      "Cornac version: 1.14.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cornac\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "\n",
    "# change dir for custom imports\n",
    "os.chdir('../')\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Cornac version: {}\".format(cornac.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'ml-latest-small'\n",
    "fields = ['userId', 'movieId', 'rating']\n",
    "data = pd.read_csv('datasets/' + DATASET_NAME + '/clean/ratings.csv', usecols=fields)\n",
    "\n",
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Model parameters\n",
    "NUM_FACTORS = 200\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415650"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the synthetic data to the whole dataset (before test split)\n",
    "midified_ratings = pd.read_csv('datasets/' + DATASET_NAME + '/modified/ratings_random_experiment.csv', usecols=fields)\n",
    "synthetic_data = midified_ratings.loc[~midified_ratings.index.isin(data.index.to_list())]\n",
    "data = pd.concat([data, synthetic_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if there's synthetic data, add it to the test set.\n",
    "# # the idea is that the new synthetic data will have different indexes, \n",
    "# # so we look for those new indexes that are not found in the initial dataset.\n",
    "# midified_ratings = pd.read_csv('datasets/' + DATASET_NAME + '/modified/ratings_random_experiment.csv', usecols=fields)\n",
    "# synthetic_data = midified_ratings.loc[~midified_ratings.index.isin(data.index.to_list())]\n",
    "\n",
    "# # concat the synthetic data with the test set\n",
    "# test = pd.concat([test, synthetic_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 385\n",
      "Number of items: 13318\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.001,\n",
    "    verbose=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017343997955322266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9e9a89a92243cabed324d033c27872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "Took 27.1703 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    bpr.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4.9185 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bpr, train, usercol='userId', itemcol='movieId', remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the prediction and true data frames have the same set of users\n",
    "common_users = set(test['userId']).intersection(set(all_predictions['userId']))\n",
    "rating_true_common = test[test['userId'].isin(common_users)]\n",
    "rating_pred_common = all_predictions[all_predictions['userId'].isin(common_users)]\n",
    "n_users = len(common_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import get_top_k_items\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "df_hit = get_top_k_items(\n",
    "    dataframe=rating_pred_common,\n",
    "    col_user='userId',\n",
    "    col_rating='prediction',\n",
    "    k=top_k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train run information\n",
    "train.to_csv('output/' + DATASET_NAME + '/train.csv', index=False)\n",
    "test.to_csv('output/' + DATASET_NAME + '/test.csv', index=False)\n",
    "df_hit.to_csv('output/' + DATASET_NAME + '/rankings.csv', index=False)\n",
    "all_predictions.to_csv('output/' + DATASET_NAME + '/all_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('group-validation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52445fb09f682e9366639e37a6414f541c6481f599d97ed36cba6ef55ea50917"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
